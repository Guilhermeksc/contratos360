"""Carregamento autom√°tico de fixtures CSV para Empresas Sancionadas (CEIS)."""

from __future__ import annotations

import logging
from datetime import datetime
from pathlib import Path
from typing import Optional

import pandas as pd
from django.db import transaction
from django.db.models.signals import post_migrate
from django.dispatch import receiver

from .models import EmpresasSancionadas

logger = logging.getLogger(__name__)

FIXTURE_DIR = Path(__file__).resolve().parent / "fixtures"


def _as_str(value) -> Optional[str]:
	"""Converte valor para string, retornando None se vazio."""
	if pd.isna(value) or value is None:
		return None
	text = str(value).strip()
	return text if text else None


def _as_date(value) -> Optional[datetime]:
	"""Converte string de data para objeto datetime."""
	if pd.isna(value) or value is None:
		return None
	
	text = str(value).strip()
	if not text or text.lower() in ("sem informa√ß√£o", "sem informacao", ""):
		return None
	
	# Tenta formatos comuns de data brasileira
	date_formats = [
		"%d/%m/%Y",
		"%d-%m-%Y",
		"%Y-%m-%d",
		"%d/%m/%y",
	]
	
	for fmt in date_formats:
		try:
			return datetime.strptime(text, fmt).date()
		except ValueError:
			continue
	
	logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel converter data: {text}")
	return None


def _load_ceis_csv():
	"""Carrega dados do arquivo CSV do CEIS."""
	csv_path = FIXTURE_DIR / "ceis.csv"
	
	if not csv_path.exists():
		logger.warning(f"üìÇ Arquivo ceis.csv n√£o encontrado em {FIXTURE_DIR}")
		return
	
	try:
		# L√™ CSV com separador ponto e v√≠rgula e encoding latin-1
		df = pd.read_csv(
			csv_path,
			sep=";",
			encoding="latin-1",
			low_memory=False,
		)
	except Exception as exc:
		logger.exception(f"‚ùå Falha ao ler ceis.csv: {exc}")
		return
	
	# Normaliza nomes das colunas (remove espa√ßos e converte para min√∫sculas)
	df.columns = df.columns.str.strip().str.lower()
	
	# Fun√ß√£o auxiliar para encontrar coluna por palavras-chave (ignora encoding)
	def find_column(keywords):
		"""Encontra uma coluna usando palavras-chave, ignorando problemas de encoding."""
		keywords_lower = [k.lower().strip() for k in keywords]
		best_match = None
		best_score = 0
		
		for col in df.columns:
			col_lower = col.lower().strip()
			# Conta quantas palavras-chave est√£o presentes
			matches = sum(1 for kw in keywords_lower if kw in col_lower)
			# Se todas as palavras-chave est√£o presentes, √© um match perfeito
			if matches == len(keywords_lower):
				return col
			# Mant√©m o melhor match parcial
			if matches > best_score:
				best_score = matches
				best_match = col
		
		# Retorna o melhor match se encontrou pelo menos uma palavra-chave
		return best_match if best_score > 0 else None
	
	# Mapeia campos do modelo para palavras-chave das colunas
	field_mapping = {
		"cadastro": ["cadastro"],
		"codigo_sancao": ["c√≥digo", "san√ß√£o"],
		"tipo_pessoa": ["tipo", "pessoa"],
		"cpf_cnpj": ["cpf", "cnpj", "sancionado"],
		"nome_sancionado": ["nome", "sancionado"],
		"nome_orgao_sancionador": ["nome", "informado", "√≥rg√£o", "sancionador"],
		"razao_social": ["raz√£o", "social", "cadastro", "receita"],
		"nome_fantasia": ["nome", "fantasia", "cadastro", "receita"],
		"numero_processo": ["n√∫mero", "processo"],
		"categoria_sancao": ["categoria", "san√ß√£o"],
		"data_inicio_sancao": ["data", "in√≠cio", "san√ß√£o"],
		"data_final_sancao": ["data", "final", "san√ß√£o"],
		"data_publicacao": ["data", "publica√ß√£o"],
		"publicacao": ["publica√ß√£o"],
		"detalhamento_meio_publicacao": ["detalhamento", "meio", "publica√ß√£o"],
		"data_transito_julgado": ["data", "tr√¢nsito", "julgado"],
		"abrangencia_sancao": ["abrang√™ncia", "san√ß√£o"],
		"orgao_sancionador": ["√≥rg√£o", "sancionador"],
		"uf_orgao_sancionador": ["uf", "√≥rg√£o", "sancionador"],
		"esfera_orgao_sancionador": ["esfera", "√≥rg√£o", "sancionador"],
		"fundamentacao_legal": ["fundamenta√ß√£o", "legal"],
		"data_origem_informacao": ["data", "origem", "informa√ß√£o"],
		"origem_informacoes": ["origem", "informa√ß√µes"],
		"observacoes": ["observa√ß√µes"],
	}
	
	# Cria mapeamento de colunas reais para campos do modelo
	column_to_field = {}
	for field_name, keywords in field_mapping.items():
		col = find_column(keywords)
		if col:
			column_to_field[col] = field_name
		else:
			logger.warning(f"‚ö†Ô∏è Coluna n√£o encontrada para campo {field_name} (keywords: {keywords})")
	
	logger.info(f"üìã Colunas mapeadas: {len(column_to_field)}/{len(field_mapping)}")
	logger.debug(f"üìã Mapeamento: {column_to_field}")
	
	processed = 0
	created = 0
	updated = 0
	
	logger.info(f"üìÑ Processando {len(df)} registros do CEIS...")
	
	for idx, row in df.iterrows():
		try:
			# Busca o c√≥digo da san√ß√£o (chave √∫nica)
			codigo_sancao_col = None
			for col_name, field_name in column_to_field.items():
				if field_name == "codigo_sancao":
					codigo_sancao_col = col_name
					break
			
			if not codigo_sancao_col:
				# Tenta encontrar diretamente
				codigo_sancao_col = find_column(["c√≥digo", "san√ß√£o"])
			
			if codigo_sancao_col and codigo_sancao_col in df.columns:
				codigo_sancao = _as_str(row.get(codigo_sancao_col))
			else:
				codigo_sancao = None
			
			if not codigo_sancao:
				logger.warning(f"‚è≠Ô∏è Linha {idx + 2} ignorada: c√≥digo da san√ß√£o n√£o encontrado")
				continue
			
			# Prepara dados para o modelo
			defaults = {}
			
			# Processa cada campo usando o mapeamento
			for col_name, field_name in column_to_field.items():
				if col_name in df.columns:
					value = row.get(col_name)
					
					# Campos de data
					if field_name.startswith("data_"):
						date_value = _as_date(value)
						if date_value:
							defaults[field_name] = date_value
					# Campos de texto
					else:
						str_value = _as_str(value)
						if str_value:
							defaults[field_name] = str_value
			
			# Cria ou atualiza o registro
			obj, was_created = EmpresasSancionadas.objects.update_or_create(
				codigo_sancao=codigo_sancao,
				defaults=defaults,
			)
			
			processed += 1
			if was_created:
				created += 1
			else:
				updated += 1
			
			if (idx + 1) % 1000 == 0:
				logger.info(f"üìä Processados {idx + 1}/{len(df)} registros...")
		
		except Exception as exc:
			logger.exception(f"‚ùå Erro ao processar linha {idx + 2}: {exc}")
			continue
	
	logger.info(
		f"‚úÖ CEIS: {processed} registros processados "
		f"({created} novos, {updated} atualizados)"
	)


@receiver(post_migrate)
def load_fixtures_ceis(sender, **kwargs):
	"""Carrega o arquivo CSV do CEIS logo ap√≥s as migra√ß√µes do app."""
	
	if sender.name != "django_licitacao360.apps.empresas_sancionadas":
		return
	
	logger.info("üì• Iniciando carga autom√°tica de dados do CEIS...")
	
	try:
		with transaction.atomic():
			_load_ceis_csv()
	except Exception as exc:
		logger.exception(f"‚ùå Erro ao carregar fixtures do CEIS: {exc}")
	else:
		logger.info("üéâ Fixtures do CEIS processadas com sucesso!")
